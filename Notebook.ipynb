{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3896a2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 14 20:38:41 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K40m          Off  | 00000000:81:00.0 Off |                    0 |\r\n",
      "| N/A   58C    P0   133W / 235W |   3648MiB / 11441MiB |     93%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      6570      C   .../mtech1/19CS60R28/miniconda3/bin/python   668MiB |\r\n",
      "|    0     37145      C   python                                      2966MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2580c598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mtech1/19CS60R28/susmit/DocRed_hongwang600/DocRed\n",
      "/home/mtech1/19CS60R28/susmit/DocRed_hongwang600\n"
     ]
    }
   ],
   "source": [
    "%cd /home/mtech1/19CS60R28/susmit/DocRed_hongwang600/DocRed\n",
    "import sys\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from pytorch_transformers import *\n",
    "from models.bert import Bert\n",
    "import seaborn as sns\n",
    "%cd ..\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466b4a45",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ddf33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path='data'\n",
    "out_path='prepro_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07fbe3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotated_file_name = os.path.join(in_path, 'train_annotated.json')\n",
    "dev_file_name = os.path.join(in_path, 'dev.json')\n",
    "test_file_name = os.path.join(in_path, 'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb90fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id = json.load(open(os.path.join(out_path, 'rel2id.json'), \"r\"))\n",
    "id2rel = {v:u for u,v in rel2id.items()}\n",
    "json.dump(id2rel, open(os.path.join(out_path, 'id2rel.json'), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5471e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are as per Bert class \n",
    "SEP='[SEP]'\n",
    "MASK = '[MASK]'\n",
    "CLS = \"[CLS]\"\n",
    "model_name='bert'\n",
    "PRE_TRAINED_MODEL_NAME='bert-base-uncased'\n",
    "\n",
    "bert = Bert(BertModel, PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8ce695d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9db4538",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5014ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(s, print_=True, log_=True):\n",
    "    if print_:\n",
    "        print(s)\n",
    "    if log_:\n",
    "        with open(os.path.join(os.path.join(\"log\", model_name+'.txt')), 'a+') as f_log:\n",
    "            f_log.write(str(s)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cb6a970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do add union of evidences=> done\n",
    "# for sent pad use 2\n",
    "\n",
    "def preprocess(data_file_name, max_length = 512, is_training = True, suffix=''):\n",
    "    ori_data=json.load(open(data_file_name))\n",
    "    max_sent_count=0#maximum number of sentences in a doc across the dataset\n",
    "    list_sent_ids=[]\n",
    "    list_attention=[]#this stores attention of docs\n",
    "    list_sent_mask=[]#this will be used in the batch multliplication for getting the embeddings of each sentence\n",
    "    # (len(list_sent_ids),max_sent_count,max_length)\n",
    "    \n",
    "    labels=[]\n",
    "    i=0\n",
    "    for doc in ori_data:\n",
    "        i=i+1\n",
    "        sys.stdout.write(\"\\r%d/%d docs\"%(i,len(ori_data)))\n",
    "        # this dict is used to take care of multiple relations with same head and tail\n",
    "        head_tail_index={}\n",
    "        max_sent_count=max(max_sent_count,len(doc['sents']))\n",
    "        for label in doc['labels']:\n",
    "            idx_list=[]\n",
    "            head=doc['vertexSet'][label['h']]\n",
    "            tail=doc['vertexSet'][label['t']]\n",
    "            if (label['h'],label['t']) in head_tail_index:\n",
    "                labels[head_tail_index[(label['h'],label['t'])]]+=label['evidence']\n",
    "                continue\n",
    "            else:\n",
    "                head_tail_index[(label['h'],label['t'])]=len(list_sent_ids)\n",
    "            for entity in head:\n",
    "                if (entity['sent_id'],entity['pos'][0],'[unused0]') not in idx_list:\n",
    "                    idx_list.append((entity['sent_id'],entity['pos'][0],'[unused0]'))\n",
    "                if (entity['sent_id'],entity['pos'][1]+1,'[unused1]') not in idx_list:\n",
    "                    idx_list.append((entity['sent_id'],entity['pos'][1]+1,'[unused1]'))\n",
    "            for entity in tail:\n",
    "                if (entity['sent_id'],entity['pos'][0],'[unused2]') not in idx_list:\n",
    "                    idx_list.append((entity['sent_id'],entity['pos'][0],'[unused2]'))\n",
    "                if (entity['sent_id'],entity['pos'][1]+1,'[unused3]') not in idx_list:\n",
    "                    idx_list.append((entity['sent_id'],entity['pos'][1]+1,'[unused3]'))\n",
    "            idx_list.sort(key=lambda tup:(tup[0],tup[1]),reverse=True)\n",
    "            temp_doc=copy.deepcopy(doc)\n",
    "            for loc in idx_list:\n",
    "                temp_doc['sents'][loc[0]].insert(loc[1],loc[2])\n",
    "\n",
    "            sent_combine=[]\n",
    "            for sent in temp_doc['sents']:\n",
    "                sent_combine=sent_combine+sent\n",
    "            sent_ids,sent_attention_mask,sent_start_ids=bert.subword_tokenize_to_ids(sent_combine)\n",
    "            list_sent_ids.append(sent_ids[0])\n",
    "            list_attention.append(sent_attention_mask[0])\n",
    "            labels.append(label['evidence'])\n",
    "            \n",
    "            \n",
    "            sent_mask=[]\n",
    "            l=1# we start from index 1 because we skip CLS token\n",
    "            for sent in temp_doc['sents']:\n",
    "                sent_mask.append([0]*max_length)\n",
    "                j=l\n",
    "#                 print(sent)\n",
    "#                 print(\"\\n\")\n",
    "                while(j<min(max_length-2,l+len(sent))):\n",
    "                    sent_mask[-1][j]=1\n",
    "                    j+=1\n",
    "                l+=len(sent)\n",
    "                if(l>=max_length-2):\n",
    "                    break\n",
    "            list_sent_mask.append(sent_mask)\n",
    "            \n",
    "    logging('')\n",
    "    evi_labels = np.zeros((len(labels),max_sent_count),dtype = np.int64)\n",
    "    for i in range(len(labels)):\n",
    "        evi_labels[i][labels[i]]=1 #if evidence present then 1\n",
    "    print(\"max_sent_cout\",max_sent_count)\n",
    "    for i in range(len(list_sent_mask)):\n",
    "        # the label for pad sentence is 2\n",
    "        evi_labels[i][len(list_sent_mask[i]):max_sent_count]=2\n",
    "        # to pad sentences with arrays of 1s\n",
    "        list_sent_mask[i]=list_sent_mask[i]+[[1]*max_length]*(max_sent_count-len(list_sent_mask[i]))\n",
    "    list_sent_ids=np.asarray(list_sent_ids,dtype=np.int64)\n",
    "    list_attention=np.asarray(list_attention,dtype=np.int64)\n",
    "    list_sent_mask=np.asarray(list_sent_mask,dtype=np.int64)\n",
    "    \n",
    "    logging(\"Started saving\")\n",
    "    \n",
    "    logging(\"Number of instances: {}\".format(list_sent_ids.shape[0]))\n",
    "    np.save(os.path.join(out_path,suffix+'_sent_ids.npy'),list_sent_ids)\n",
    "    np.save(os.path.join(out_path,suffix+'_sent_attention_mask.npy'),list_attention)\n",
    "    np.save(os.path.join(out_path,suffix+'_sent_mask.npy'),list_sent_mask)\n",
    "    np.save(os.path.join(out_path,suffix+'_evidence_labels.npy'),evi_labels)\n",
    "    logging(\"completed saving\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aed4fac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3053/3053 docs\n",
      "max_sent_cout 25\n",
      "Started saving\n",
      "Number of instances: 35615\n",
      "completed saving\n",
      "\n",
      "1000/1000 docs\n",
      "max_sent_cout 21\n",
      "Started saving\n",
      "Number of instances: 11518\n",
      "completed saving\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess(train_annotated_file_name, max_length = 512, is_training = False, suffix='train')\n",
    "preprocess(dev_file_name, max_length = 512, is_training = False, suffix='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099e653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab41a464",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62dd2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb2a6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Docred_dataset(Dataset):\n",
    "    def __init__(self,sent_ids,sent_mask,evi_target,max_len):\n",
    "        self.sent_ids=sent_ids\n",
    "        self.sent_mask=sent_mask\n",
    "        self.ev_target=evi_target\n",
    "    def __len__(self):\n",
    "        return evi_target.shape[0]\n",
    "    def __getitem__(self,item):\n",
    "        return {\n",
    "            'input_ids':torch.tensor(sent_ids,dtype=torch.long).flatten(),\n",
    "            'attention_masks':torch.tensor(sent_mask,dtype=torch.long).flatten(),\n",
    "            'targets':torch.tensor(evi_target,dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8ac529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_ids=np.load(os.path.join(out_path,'train'+'_sent_ids.npy'))\n",
    "sent_mask=np.load(os.path.join(out_path,'train'+'_sent_mask.npy'))\n",
    "evi_target=np.load(os.path.join(out_path,'train'+'_evidence_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00dd8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(max_len,batch_size):\n",
    "    ds=Docred(sent_ids,sent_mask,evi_target,max_len=512)\n",
    "    return DataLoader(ds,batch_size=batch_size,num_workers=4)\n",
    "BATCH_SIZE=8\n",
    "MAX_LEN=512\n",
    "train_data_loader=create_data_loader(max_len=MAX_LEN,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e55784ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_masks', 'targets'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fbab95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 61440])\n",
      "torch.Size([8, 61440])\n",
      "torch.Size([8, 120, 12])\n"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_masks'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464879a6",
   "metadata": {},
   "source": [
    "### Evidence calssification using Bert and Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "354d5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c49b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_mask = (b,k,t)\n",
    "# k=max sent length\n",
    "# output =(b,t,h)\n",
    "# torch.bmm\n",
    "# (b,k,t)*(b,t,h)/(len(sent))==(b,k,h)\n",
    "# torch.sum(dim)  torch.sum(input, dim, keepdim=False, *, dtype=None) â†’ Tensor\n",
    "\n",
    "\n",
    "class EvidenceClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(EvidenceClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME,return_dict=False)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    def forward(self, input_ids, attention_mask,sent_mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        output = self.drop(pooled_output)\n",
    "#         #BMM\n",
    "#         2\n",
    "#             10->3sent\n",
    "#             5->2sent\n",
    "#             sent_mask=(2,3,10)\n",
    "#             length of each sent mask->10\n",
    "#             1st doc->1st sent(0,3)\n",
    "#             each sent_mask=[1,1,1,1,0,0,0,...]\n",
    "#             2nd doc ->(pad sent) use all ones \n",
    "#             2nd doc->3rd sent->[1,1,1,...](to divide zero issue)\n",
    "#             bert_output->(2,10,768)\n",
    "#             sent_mask*bert_output(BMM)\n",
    "#             output=(2,3,768)=(2,3,10)*(2,10,768)\n",
    "#             output(2,3,3)=Linear(output,3)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc38844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         loss(input(output of the model),target)\n",
    "            #no_evidence_sent=>lablel=0\n",
    "            #evidence_sent=>label=1\n",
    "            #evidence_pad=>lebel=2\n",
    "#             loss(ignore_index=2) \n",
    "#             NLLLoss\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html?highlight=nllloss#torch.nn.NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb625340",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "393f7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(tokenizer.encode(\"[CLS] Hello my dog is cute\")).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "last_hidden_state, pooler_output = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6bf75b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_state.shape)\n",
    "print(pooler_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4589521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.0670e-02, -1.3634e-01, -2.0471e-01,  1.3662e-01, -5.4963e-02,\n",
      "         1.3121e-01, -1.6027e-01, -1.4354e-01, -3.3725e-01, -2.0080e-01,\n",
      "        -3.8223e-02,  2.4945e-01, -3.3377e-01, -1.7753e-01, -4.1003e-01,\n",
      "         7.3531e-01, -3.7430e-02, -7.1812e-02, -4.7473e-01, -5.2340e-02,\n",
      "         3.7171e-01, -1.2110e-01,  1.4048e-01, -6.6024e-02,  4.0694e-01,\n",
      "        -1.5038e-01,  6.9376e-01,  3.7555e-03, -3.3062e-01, -8.2766e-02,\n",
      "        -6.4227e-02, -2.2916e-01,  2.4486e-01,  1.0927e-01,  2.3430e-01,\n",
      "        -3.7256e-01, -3.8063e-02, -2.4527e-01, -3.1919e-01,  5.5296e-01,\n",
      "        -9.9116e-02, -5.8969e-01, -7.5447e-02,  2.0883e-01, -2.2657e-01,\n",
      "        -1.2772e-01, -1.1553e+00,  1.5863e-01,  2.9359e-01, -3.7036e-01,\n",
      "        -4.3070e-01,  9.0894e-02,  6.8570e-02,  2.1841e-01,  2.0635e-02,\n",
      "         1.8272e-01,  1.3496e-01, -1.7807e-01,  8.3814e-02,  1.2017e-01,\n",
      "         7.9420e-02, -3.5725e-01,  6.3858e-03, -8.3377e-02, -1.4762e-01,\n",
      "         1.3408e-01,  6.4399e-02,  6.1005e-02,  4.5285e-02, -2.3808e-01,\n",
      "        -6.1145e-03,  1.7697e-01, -2.8100e-02, -3.3854e-01,  3.8658e-02,\n",
      "         3.2634e-01,  3.8668e-01,  8.2142e-02,  6.7604e-01,  5.8754e-01,\n",
      "         1.7991e-01,  1.1500e-01, -2.4294e-01, -1.5504e-01,  2.7279e-01,\n",
      "        -9.0191e-02, -2.5124e-01,  5.5583e-01, -1.7069e-01,  3.5618e-01,\n",
      "         9.3429e-02, -5.6838e-02, -1.1827e-01,  4.9610e-01,  6.2939e-01,\n",
      "        -2.7113e-01, -1.2476e-01, -1.5627e-02, -1.5769e-01, -2.1777e-01,\n",
      "        -4.0148e-01, -4.8300e-01, -1.8780e-01, -3.3087e-01, -3.9055e-01,\n",
      "        -5.2448e-01, -5.4817e-02, -3.3972e-01, -5.0848e-01,  9.5129e-04,\n",
      "         4.7641e-01,  4.9015e-01, -1.2338e-01, -2.6611e-01, -9.2908e-02,\n",
      "        -1.1822e-01,  5.6576e-01,  6.4616e-01, -1.6666e-01, -3.8727e-02,\n",
      "        -9.4601e-02,  6.6427e-01,  6.5799e-01, -8.5061e-03,  6.1355e-01,\n",
      "         1.8959e-01, -3.2752e-01,  4.9061e-02, -3.1207e-01,  3.3152e-01,\n",
      "         3.8839e-01, -8.1400e-02, -3.9633e-02,  8.5824e-02,  1.0139e-01,\n",
      "         6.0950e-02,  1.6981e-01,  1.2951e-01, -1.2923e-02, -8.1191e-01,\n",
      "        -4.5794e-01,  5.6637e-01, -4.5696e-01,  2.1501e-01, -9.3912e-02,\n",
      "        -7.9060e-02, -1.8905e-01,  2.6032e-01,  1.2704e-01,  5.2357e-01,\n",
      "         2.0965e-01,  3.1164e-01, -3.2993e-01,  1.4976e-01,  3.7188e-01,\n",
      "        -2.9105e-01,  1.6555e-01, -3.4594e-01, -3.0729e-01,  9.5400e-02,\n",
      "        -9.3617e-02,  6.4189e-01, -3.8956e-01, -6.2579e-01,  8.2723e-01,\n",
      "        -5.7609e-01,  2.1946e-01,  2.1674e-01,  3.1309e-01,  1.6932e-01,\n",
      "        -3.9091e-01, -5.6086e-01,  6.9283e-01, -6.6944e-02,  2.3089e-01,\n",
      "         2.2110e-01,  2.1105e-01, -2.0513e-01,  1.1946e-02,  2.5107e-01,\n",
      "        -4.1799e-01, -2.4483e-01,  1.2225e-01,  1.2067e-01,  3.5423e-01,\n",
      "        -1.3493e-01,  7.3790e-01,  7.9429e-02,  1.1379e-01,  4.2209e-01,\n",
      "        -6.7140e-01,  9.1218e-02,  3.0111e-01, -1.2832e-01,  8.0110e-01,\n",
      "        -4.4843e-01, -5.3054e-01,  4.6373e-01,  3.5025e-01, -2.7214e-01,\n",
      "         1.2536e-01,  1.6835e-01,  1.1945e-01, -7.1759e-02, -5.6155e-01,\n",
      "         4.8068e-01,  1.6906e-01,  3.0359e-02, -3.2237e-01, -2.7724e-01,\n",
      "         1.3011e-01, -4.2121e-02,  3.1505e-01, -5.0716e-01, -2.2943e-02,\n",
      "         1.5297e-02,  4.8897e-01,  1.8307e-01,  5.9262e-02,  5.5339e-01,\n",
      "        -2.7824e-01, -2.6249e-01,  2.6065e-01,  3.8002e-01,  2.3622e-01,\n",
      "         1.0471e+00,  5.9572e-01, -4.8491e-01,  1.9936e-01,  3.2621e-01,\n",
      "         2.6972e-02, -5.6112e-01, -1.8672e-04,  6.2771e-02, -2.8249e-02,\n",
      "        -1.4782e-01,  5.5872e-02, -2.4851e-01,  4.0380e-01,  6.0771e-02,\n",
      "        -1.8198e-01,  2.1664e-01, -4.5631e-01,  5.4344e-01, -2.8929e-01,\n",
      "        -4.9055e-02,  2.9516e-01, -1.8229e-01,  9.6365e-02,  2.8300e-02,\n",
      "        -7.5037e-01,  5.3339e-02,  3.2481e-01, -2.6884e-01,  7.2732e-02,\n",
      "        -5.8198e-01,  2.8004e-01, -2.9368e-02,  3.3541e-01,  2.8654e-01,\n",
      "        -3.1993e-01,  6.5589e-02,  1.3154e-02, -7.7278e-01, -6.9445e-02,\n",
      "        -2.3428e-01, -5.6268e-01,  9.4836e-03,  2.5442e-01,  5.0111e-01,\n",
      "        -2.3648e-01,  3.6198e-01, -3.6619e-01, -3.2651e-01, -5.6950e-01,\n",
      "         1.5759e-01,  5.6836e-01,  2.7398e-01, -3.2996e-01,  9.7086e-02,\n",
      "        -2.7419e-01,  1.4893e-01,  1.4785e-01, -1.5884e-01, -7.6245e-01,\n",
      "        -3.6541e-01,  6.8311e-01, -3.1263e-01, -3.8060e-01,  1.3751e-02,\n",
      "        -5.9320e-01, -2.0436e-02, -2.4547e-02, -3.5834e-01,  1.5423e-01,\n",
      "         4.7688e-01,  1.8803e-01,  2.7901e-01,  5.1095e-02, -1.4553e-01,\n",
      "         3.7508e-01,  2.5280e-01, -4.6254e-01,  5.9332e-02,  1.5323e-01,\n",
      "         1.6456e-01, -1.0883e-02,  1.5853e-01, -6.0548e+00, -3.0377e-02,\n",
      "         9.8517e-02, -1.0090e-01,  4.0134e-01,  6.6042e-01,  3.4911e-01,\n",
      "        -3.0194e-01, -4.7988e-01, -2.0130e-01,  2.3902e-01,  3.2203e-01,\n",
      "        -3.0887e-02, -1.1546e-02,  1.9120e-01, -5.7216e-01,  5.4741e-01,\n",
      "         1.7779e-01,  3.6092e-01,  8.7678e-01,  7.2050e-01,  2.4225e-01,\n",
      "        -3.0164e-01, -2.2290e-02, -6.0857e-01, -1.6475e-01, -1.0675e-01,\n",
      "        -1.1736e-01, -5.8242e-01, -2.8254e-01,  3.5125e-01,  7.5109e-02,\n",
      "        -5.8452e-02, -4.5777e-01, -5.9332e-02,  2.7468e-01,  2.6966e-01,\n",
      "         2.0460e-01,  4.9355e-01,  4.5522e-01, -1.7106e-01, -1.1231e-01,\n",
      "         2.2365e-01,  1.1321e-01,  2.2739e-01, -4.1229e-02,  7.2466e-01,\n",
      "        -2.8813e-01,  2.9132e-01,  2.6923e-01, -2.6339e-01,  3.4941e-01,\n",
      "         3.8967e-02, -4.9287e-01,  5.8889e-01,  4.7951e-01, -5.5226e-01,\n",
      "         1.2943e-02,  1.7956e-01, -1.3803e-01,  2.8594e-01,  6.1296e-01,\n",
      "        -1.6192e-01,  2.9537e-01, -5.3198e-01, -3.3743e-01, -3.9099e-01,\n",
      "        -2.2374e-01,  2.6477e-01,  4.0733e-01, -6.2964e-01,  5.6592e-01,\n",
      "         1.6762e-01, -1.2823e+00, -1.8082e-01, -1.7545e-01,  1.7935e-01,\n",
      "        -4.3313e-01,  4.0988e-01,  1.3816e-01, -1.0740e+00, -1.4152e-01,\n",
      "         3.0097e-01,  6.9357e-01, -5.7851e-01,  9.3085e-02, -2.3720e-01,\n",
      "        -4.4731e-02, -1.0131e-01,  2.9764e-01, -3.0214e-01,  7.0212e-02,\n",
      "        -2.2226e-01, -1.7850e-01,  6.4815e-01,  3.5009e-01,  5.0753e-01,\n",
      "        -3.6662e-02, -8.5234e-03, -6.1378e-03,  1.7692e-01,  2.8980e-01,\n",
      "        -2.6053e-01, -5.0099e-01, -5.5641e-02,  3.0773e-01, -6.7122e-01,\n",
      "         2.4447e-01,  2.4940e-01, -4.4930e-01, -1.3702e-01, -2.2826e-01,\n",
      "        -4.0107e-01, -2.2334e-01,  8.0851e-01, -4.4940e-01,  2.3880e-01,\n",
      "         2.0149e-01, -5.5644e-02, -7.0792e-01, -4.2703e-01,  1.0640e-01,\n",
      "        -2.0863e-01, -3.8254e-01,  3.9417e-02,  3.6718e-03, -2.2604e-01,\n",
      "        -5.2237e-02, -1.0987e-03,  4.3527e-01,  1.3129e-01, -9.6496e-02,\n",
      "        -2.5291e-01, -4.5053e-01, -1.5394e-01, -1.1128e-01, -4.8597e-01,\n",
      "        -1.8712e-01, -4.1350e-01, -4.7174e-01, -3.0302e-01,  3.0664e-02,\n",
      "        -1.3530e-01,  1.2126e-02,  6.9402e-01, -1.5078e-01, -2.8754e-03,\n",
      "         1.3768e-01, -5.2465e-02, -3.8849e-01,  4.9279e-01, -1.5447e-01,\n",
      "         4.6784e-01, -3.4071e-01,  2.5511e-01, -1.1344e-02,  8.6312e-01,\n",
      "         3.3847e-01,  4.4038e-02, -5.8312e-01,  4.3119e-01, -5.3601e-01,\n",
      "        -5.8254e-01,  4.8920e-01,  1.1502e-01,  7.4487e-02,  9.6547e-02,\n",
      "        -1.5216e-01,  4.7655e-01, -4.5116e-01, -6.0010e-01, -5.6848e-01,\n",
      "        -2.0165e-01,  7.3994e-03,  2.3567e-01,  8.8103e-01, -3.2549e-01,\n",
      "        -4.9234e-01, -4.9095e-01, -9.5935e-02,  3.4108e-01,  2.3615e-01,\n",
      "         2.8399e-01,  2.5241e-01,  2.0215e-01, -1.9231e-01,  2.7839e-01,\n",
      "        -2.6183e-01,  4.0679e-02,  2.2757e-01,  9.2176e-02, -2.4129e-02,\n",
      "         6.8525e-01, -4.4971e-01, -4.0950e-01, -1.2406e-01,  2.9179e-01,\n",
      "         2.8523e-01,  1.0163e-01,  1.9894e-01, -7.4675e-01, -2.5396e-01,\n",
      "        -1.7512e-01, -2.7821e-01,  2.8373e-02,  8.8595e-02, -3.3344e-01,\n",
      "        -9.9887e-02, -7.3315e-01, -3.5259e-03, -8.3068e-02, -4.0823e-01,\n",
      "        -2.0564e-01, -3.1591e-01,  4.2023e-01, -2.7925e-01, -2.8455e-01,\n",
      "         3.8173e-01, -1.6438e-01, -3.0124e-01, -5.0536e-01, -3.7790e-01,\n",
      "         1.8838e-01,  4.2690e-02,  7.7400e-01, -3.1922e-01, -3.3940e-01,\n",
      "        -4.5403e-01, -5.3809e-02,  7.0686e-01,  9.9969e-02, -4.2181e-01,\n",
      "         1.2133e-01, -4.2881e-01, -4.5995e-01,  1.2228e-01, -2.2560e-01,\n",
      "        -5.9140e-01, -4.3435e-01,  3.3832e-01,  4.3347e-01, -1.8303e-01,\n",
      "         1.0759e-01,  1.3245e-01, -3.7505e-01,  1.0473e-01,  2.8424e-01,\n",
      "        -3.9815e-01, -2.1871e-02,  5.4024e-01,  2.6952e-02, -2.4077e-01,\n",
      "         2.1283e-01, -6.2613e-01,  3.0248e-01,  1.0520e-01,  9.3936e-03,\n",
      "        -5.6524e-01, -3.0081e-01,  2.6008e-01,  2.9176e-01,  7.1096e-01,\n",
      "        -8.7372e-02, -5.5149e-02, -5.5669e-02, -4.3080e-02, -1.9224e-01,\n",
      "        -5.2204e-01,  1.2399e+00, -1.8669e-02, -4.0121e-02,  1.4456e-01,\n",
      "        -1.7521e-01,  7.1923e-01, -1.5330e-02,  3.6183e-01, -1.8895e-01,\n",
      "         4.4982e-01, -9.6139e-02,  1.9134e-01,  9.0836e-02,  2.1980e-01,\n",
      "         3.0459e-01, -1.1125e-01,  2.8583e-01,  1.8602e-01, -9.2442e-02,\n",
      "         1.0400e-01,  4.8221e-02,  5.6868e-01,  4.3810e-02,  5.1556e-01,\n",
      "        -2.3345e-01, -9.3114e-01, -1.6502e-01, -5.2246e-03, -2.3111e-01,\n",
      "        -9.1214e-02, -4.5823e-01, -3.4274e-01, -2.2444e-03,  9.7066e-02,\n",
      "         8.8344e-01, -5.3850e-01, -6.4993e-02,  3.5285e-01,  2.5690e-01,\n",
      "         2.4676e-01,  2.9808e-02, -2.7261e-01,  8.6791e-02,  9.2472e-02,\n",
      "        -1.2898e-01,  9.3388e-01, -5.0430e-01, -2.7177e-02, -1.5232e-01,\n",
      "         9.1186e-02,  1.8817e-01,  4.6572e-01,  2.2032e-01,  6.5847e-01,\n",
      "        -5.6712e-02, -2.2068e-01, -1.6899e-01,  6.0615e-02,  1.5566e-01,\n",
      "        -3.0820e-01, -1.1214e-01,  4.5215e-02,  1.6870e-01,  7.8718e-02,\n",
      "         8.9135e-01,  9.7584e-02, -1.5633e-01, -2.9395e-01,  2.4067e-01,\n",
      "        -4.9243e-01, -7.6747e-03,  2.9871e-01, -3.1045e-01,  3.7689e-02,\n",
      "        -3.6180e-02,  1.0179e-01,  6.6305e-01,  4.1826e-03,  4.1491e-02,\n",
      "         4.4507e-02, -9.7574e-02,  3.6479e-01,  3.2963e-01,  9.5508e-02,\n",
      "        -2.0415e-01,  6.4603e-02, -6.5963e-01,  8.0868e-03,  2.8762e-01,\n",
      "        -3.0538e-01,  1.0490e-01, -4.6194e-01,  1.0739e-01,  6.2004e-01,\n",
      "         1.3809e-01,  1.6968e-01,  1.0601e-01,  2.5904e-01,  9.8523e-01,\n",
      "         1.6600e-01, -2.1538e-02,  8.0920e-02, -1.6826e-01, -2.1515e-01,\n",
      "        -3.4890e-01,  5.1422e-01, -2.1895e-01,  1.4944e-01, -6.6952e-02,\n",
      "         2.0108e-01, -1.8435e-02,  3.1447e-02,  2.5955e-01,  2.9532e-02,\n",
      "        -3.9951e-01,  2.2303e-01, -1.3844e-01, -4.8558e-01, -3.6452e-01,\n",
      "         2.3689e-01,  1.6811e-01, -6.3965e-01, -1.1382e-01, -1.7064e-01,\n",
      "         1.4207e-01,  5.2472e-01, -2.8317e-01, -5.7716e-01,  6.9317e-01,\n",
      "        -2.8477e-01,  4.7681e-01, -4.4627e-02, -8.5338e-02,  1.7336e-01,\n",
      "        -6.6360e-02,  2.6354e-01,  1.3288e-01,  6.1161e-02,  5.2909e-01,\n",
      "         4.1816e-01, -7.3005e-01, -2.4559e-01,  4.0560e-01,  1.5353e-01,\n",
      "        -1.9581e-01,  4.1390e-02, -3.8082e-01, -3.2538e-01,  7.1491e-01,\n",
      "        -2.4557e-01, -2.4244e-01, -9.4245e-02,  3.6146e-01,  2.3060e-01,\n",
      "         1.8436e-01, -2.4290e-01, -7.3558e-01, -5.2675e-01,  3.3562e-01,\n",
      "         1.1282e-01, -5.7680e-01,  2.7931e-01,  2.0371e-02, -3.3092e-01,\n",
      "         3.0354e-02,  5.2424e-01, -3.8031e-01, -1.8150e-01,  5.6742e-01,\n",
      "        -2.2654e-01,  1.0837e-01, -3.3414e-01,  1.9970e-02,  1.6368e-01,\n",
      "        -5.4821e-01, -1.0946e-03, -9.1081e-01,  6.9185e-02,  3.6411e-02,\n",
      "        -5.4671e-01, -2.6143e-01, -5.5726e-01, -3.9812e-01, -2.5101e-01,\n",
      "        -4.1600e-01,  1.7794e-01,  4.3386e-01, -2.6294e-01, -4.0305e-01,\n",
      "        -5.2386e-01,  1.7410e-01,  7.9549e-01], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_state[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ede530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
