{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import shutil\n",
    "# os.chdir(\"/home/mtech1/19CS60R28/susmit/DocRed_hongwang600/DocRed\")\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from pytorch_transformers import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.autograd as autograd\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"/home/mtech1/19CS60R28/susmit/DocRed_hongwang600/DocRed/models\")\n",
    "from bert import Bert\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"/home/mtech1/19CS60R28/susmit/DocRed_hongwang600\")\n",
    "RANDOM_SEED = 42\n",
    "in_path='data'\n",
    "out_path='prepro_data'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0,1\"\n",
    "PRE_TRAINED_MODEL_NAME='bert-base-uncased'\n",
    "save_model_file = os.path.join('checkpoint', 'model.h5py')\n",
    "model_name='bert'\n",
    "BATCH_SIZE=4# for training\n",
    "BATCH_SIZE_PRED=4\n",
    "EPOCH = 100\n",
    "update_freq = 4\n",
    "early_stop_count = 5\n",
    "\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "\n",
    "MAX_LEN=512\n",
    "SEP='[SEP]'\n",
    "MASK = '[MASK]'\n",
    "CLS = \"[CLS]\"\n",
    "bert = Bert(BertModel, PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotated_file_name = os.path.join(in_path, 'train_annotated.json')\n",
    "dev_file_name = os.path.join(in_path, 'dev.json')\n",
    "test_file_name = os.path.join(in_path, 'test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(*msg):\n",
    "    for i in range(0,len(msg)):\n",
    "        if(i==len(msg)-1):\n",
    "            end='\\n'\n",
    "        else:\n",
    "            end=' '\n",
    "        print(msg[i],end=end)\n",
    "        with open(os.path.join(os.path.join(\"log\", model_name+'.txt')), 'a+') as f_log:\n",
    "            f_log.write(str(msg[i])+end)\n",
    "            f_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_random_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_fpath)\n",
    "    except OSError as e:\n",
    "        return -1,-1,-1.0,0,model,optimizer \n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return checkpoint['best_epoch_idx'], checkpoint['best_epoch_seed'], checkpoint['best_dev_acc'], checkpoint['epoch'], model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_dir, best_model_dir):\n",
    "    f_path = checkpoint_dir+'/checkpoint.pt'\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "            best_fpath = best_model_dir+'/best_model.pt'\n",
    "            shutil.copyfile(f_path, best_fpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_file_name, max_length = 512, is_training = True, suffix=''):\n",
    "    \"\"\"\n",
    "    inserts unused tokens and saves them in a dict\n",
    "    \"\"\"\n",
    "    ori_data=json.load(open(data_file_name))[0:10]\n",
    "    max_sent_count=0#maximum number of sentences in a doc across the dataset\n",
    "    # list_sent_ids=[]\n",
    "    # list_attention=[]#this stores attention of docs\n",
    "    # list_sent_mask=[]#this will be used in the batch multliplication for getting the embeddings of each sentence\n",
    "    # (len(list_sent_ids),max_sent_count,max_length)\n",
    "    input_sent = []\n",
    "    labels=[]\n",
    "    i=0\n",
    "    for doc in tqdm(ori_data):\n",
    "        i=i+1\n",
    "        # sys.stdout.write(\"\\r%d/%d docs\"%(i,len(ori_data)))\n",
    "        # this dict is used to take care of multiple relations with same head and tail\n",
    "        head_tail_index={}\n",
    "        max_sent_count=max(max_sent_count,len(doc['sents']))\n",
    "        for label in doc['labels']:\n",
    "            idx_list=[]\n",
    "            head=doc['vertexSet'][label['h']]\n",
    "            tail=doc['vertexSet'][label['t']]\n",
    "            if (label['h'],label['t']) in head_tail_index:\n",
    "                labels[head_tail_index[(label['h'],label['t'])]]+=label['evidence']\n",
    "                continue\n",
    "            else:\n",
    "                head_tail_index[(label['h'],label['t'])]=len(input_sent)\n",
    "            for entity in head:\n",
    "                if (entity['sent_id'],entity['pos'][0],'[unused0]') not in idx_list:\n",
    "                    idx_list.append((entity['sent_id'],entity['pos'][0],'[unused0]'))\n",
    "                if (entity['sent_id'],entity['pos'][1],'[unused1]') not in idx_list:\n",
    "                    idx_list.append((entity['sent_id'],entity['pos'][1],'[unused1]'))\n",
    "            for entity in tail:\n",
    "                if (entity['sent_id'],entity['pos'][0],'[unused2]') not in idx_list:\n",
    "                    idx_list.append((entity['sent_id'],entity['pos'][0],'[unused2]'))\n",
    "                if (entity['sent_id'],entity['pos'][1],'[unused3]') not in idx_list:\n",
    "                    idx_list.append((entity['sent_id'],entity['pos'][1],'[unused3]'))\n",
    "            idx_list.sort(key=lambda tup:(tup[0],tup[1]),reverse=True)\n",
    "            temp_doc=copy.deepcopy(doc)\n",
    "            for loc in idx_list:\n",
    "                temp_doc['sents'][loc[0]].insert(loc[1],loc[2])\n",
    "\n",
    "            # sent_combine=[]\n",
    "            # for sent in temp_doc['sents']:\n",
    "            #     sent_combine=sent_combine+sent\n",
    "            # sent_ids,sent_attention_mask,sent_start_ids=bert.subword_tokenize_to_ids(sent_combine)\n",
    "            # list_sent_ids.append(sent_ids[0])\n",
    "            # list_attention.append(sent_attention_mask[0])\n",
    "            input_sent.append(temp_doc['sents'])\n",
    "            labels.append(label['evidence'])\n",
    "            \n",
    "            \n",
    "            # sent_mask=[]\n",
    "            # l=1# we start from index 1 because we skip CLS token\n",
    "            # for sent in temp_doc['sents']:\n",
    "                # sent_mask.append([0]*max_length)\n",
    "                # j=l\n",
    "                # while(j<min(max_length-2,l+len(sent))):\n",
    "                    # sent_mask[-1][j]=1\n",
    "                    # j+=1\n",
    "                # l+=len(sent)\n",
    "                # if(l>=max_length-2):\n",
    "                    # break\n",
    "            # list_sent_mask.append(sent_mask)\n",
    "            \n",
    "    # logging('')\n",
    "    # evi_labels = np.zeros((len(labels),max_sent_count),dtype = np.int64)\n",
    "    # for i in range(len(labels)):\n",
    "    #     evi_labels[i][labels[i]]=1 #if evidence present then 1\n",
    "    # logging(\"max_sent_cout\",max_sent_count)\n",
    "    # for i in range(len(list_sent_mask)):\n",
    "    #     # the label for pad sentence is 2\n",
    "    #     evi_labels[i][len(list_sent_mask[i]):max_sent_count]=2\n",
    "    #     # to pad sentences with arrays of 1s\n",
    "    #     list_sent_mask[i]=list_sent_mask[i]+[[1]*max_length]*(max_sent_count-len(list_sent_mask[i]))\n",
    "    # list_sent_ids=np.asarray(list_sent_ids,dtype=np.int64)\n",
    "    # list_attention=np.asarray(list_attention,dtype=np.int64)\n",
    "    # list_sent_mask=np.asarray(list_sent_mask,dtype=np.int64)\n",
    "    data={}\n",
    "    data['input_sent']=input_sent\n",
    "    data['labels']=labels\n",
    "    logging(\"Number of instances: {}\".format(len(input_sent)))\n",
    "    logging(\"Started saving\")\n",
    "    out_file = open(os.path.join(out_path,suffix+'_data.json'),\"w\")\n",
    "    json.dump(data,out_file,indent=2)\n",
    "    out_file.close()\n",
    "    \n",
    "    # np.save(os.path.join(out_path,suffix+'_sent_ids.npy'),list_sent_ids)\n",
    "    # np.save(os.path.join(out_path,suffix+'_sent_attention.npy'),list_attention)\n",
    "    # np.save(os.path.join(out_path,suffix+'_sent_mask.npy'),list_sent_mask)\n",
    "    # np.save(os.path.join(out_path,suffix+'_evidence_labels.npy'),evi_labels)\n",
    "    logging(\"completed saving\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 184.57it/s]\n",
      "Number of instances: 111\n",
      "Started saving\n",
      "completed saving\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 111.44it/s]\n",
      "Number of instances: 161\n",
      "Started saving\n",
      "completed saving\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess(train_annotated_file_name, max_length = 512, is_training = False, suffix='train')\n",
    "preprocess(dev_file_name, max_length = 512, is_training = False, suffix='dev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open(os.path.join(out_path,'train_data.json'),'r'))\n",
    "dev_data = json.load(open(os.path.join(out_path,'dev_data.json'),'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max(cur_samples):\n",
    "    max_doc_len = 0\n",
    "    max_sent_count = 0\n",
    "    for doc in cur_samples:\n",
    "        s=0\n",
    "        for sent in doc:\n",
    "            s += len(sent)\n",
    "        max_doc_len = max(max_doc_len,s)\n",
    "        max_sent_count = max(max_sent_count,len(doc))\n",
    "\n",
    "    return max_doc_len,max_sent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_data(cur_samples_doc,cur_samples_evi = None):\n",
    "    \"\"\"\n",
    "    input is a list of docs\n",
    "    each doc is list of sentences\n",
    "    each sent is a list of tokens\n",
    "    Returns dictionary of training samples and labels as numpy array\n",
    "    \"\"\"\n",
    "    no_samples = len(cur_samples_doc)\n",
    "    max_doc_len,max_sent_count = get_max(cur_samples_doc)\n",
    "    max_doc_len+=2 # because we are going to add tokens\n",
    "    max_doc_len = min(MAX_LEN,max_doc_len)\n",
    "    input_ids = np.zeros((no_samples,max_doc_len))\n",
    "    sent_attention = np.zeros((no_samples,max_doc_len))\n",
    "    sent_mask = np.zeros((no_samples,max_sent_count, max_doc_len))# required for averaging the sentence embeddings\n",
    "    evi_target = np.zeros((no_samples,max_sent_count))\n",
    "    for i in range(no_samples):\n",
    "        lower_index = 1# 1 because CLS token is to be appended\n",
    "        doc=[]\n",
    "        j=0\n",
    "        for sent in cur_samples_doc[i]:\n",
    "            if(lower_index>=510):\n",
    "                break\n",
    "            doc+=sent\n",
    "            sent_mask[i][j][lower_index:min(lower_index+len(sent),510)]=1.0\n",
    "            lower_index+=len(sent)\n",
    "            lower_index=min(lower_index,510)\n",
    "            if(lower_index==510):\n",
    "                doc=doc[:510]\n",
    "            j+=1\n",
    "        if j<max_sent_count:\n",
    "            sent_mask[i][j:,:]=1.0\n",
    "        sent_ids,attention,start_ids = bert.subword_tokenize_to_ids(doc,max_doc_len)\n",
    "        input_ids[i],sent_attention[i]=sent_ids[0],attention[0]\n",
    "        # _,_,_ = bert.subword_tokenize_to_ids(doc,max_doc_len+2)\n",
    "        if cur_samples_evi != None :\n",
    "            evi_target[i][cur_samples_evi[i]]=1\n",
    "            if j<max_sent_count:\n",
    "                evi_target[i][j:]=2\n",
    "    return {\n",
    "        'sent_ids':input_ids,\n",
    "        'sent_attention':sent_attention,\n",
    "        'sent_mask':sent_mask,\n",
    "        'targets':evi_target,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_batch_data(train_data['input_sent'][16*BATCH_SIZE:17*BATCH_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_doc=[\n",
    "#     [['how','are','you'],['i','am','doing','good','what','about','you']],\n",
    "#     [['this','is','not','the','way'],['ok'],['continue']],\n",
    "# ]\n",
    "# data = get_batch_data(sample_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(data['sent_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Docred_dataset(Dataset):\n",
    "#     def __init__(self,sent_ids,sent_attention,sent_mask,evi_target,max_len=512):\n",
    "#         self.sent_ids=torch.from_numpy(sent_ids)\n",
    "#         self.sent_attention=torch.from_numpy(sent_attention)\n",
    "#         self.sent_mask=torch.from_numpy(sent_mask)\n",
    "#         self.evi_target=torch.from_numpy(evi_target)\n",
    "#         self.no_samples=evi_target.shape[0]\n",
    "#     def __len__(self):\n",
    "#         return evi_target.shape[0]\n",
    "#     def __getitem__(self,index):\n",
    "#         return {\n",
    "#             'sent_ids':self.sent_ids[index],\n",
    "#             'sent_attention':self.sent_attention[index],\n",
    "#             'sent_mask':self.sent_mask[index],\n",
    "#             'targets':self.evi_target[index]\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_ids=np.load(os.path.join(out_path,'train'+'_sent_ids.npy'))\n",
    "# sent_attention=np.load(os.path.join(out_path,'train'+'_sent_attention.npy'))\n",
    "# sent_mask=np.load(os.path.join(out_path,'train'+'_sent_mask.npy'))\n",
    "# evi_target=np.load(os.path.join(out_path,'train'+'_evidence_labels.npy'))\n",
    "\n",
    "# dev_sent_ids=np.load(os.path.join(out_path,'dev'+'_sent_ids.npy'))\n",
    "# dev_sent_attention=np.load(os.path.join(out_path,'dev'+'_sent_attention.npy'))\n",
    "# dev_sent_mask=np.load(os.path.join(out_path,'dev'+'_sent_mask.npy'))\n",
    "# dev_evi_target=np.load(os.path.join(out_path,'dev'+'_evidence_labels.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidenceClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EvidenceClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.dense = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    def forward(self, input_ids, attention_mask,sent_mask,is_training=False):\n",
    "        last_hidden_state, pooled_output = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        sent_mask=sent_mask.float()\n",
    "        output=torch.bmm(sent_mask,last_hidden_state)/sent_mask.sum(axis=2)[...,None]\n",
    "        logits = self.dense(output)\n",
    "        if is_training:\n",
    "            return self.logsoftmax(logits)\n",
    "        else:\n",
    "            return self.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data,dev_data,model_file):\n",
    "    input_sent = train_data['input_sent']\n",
    "    target = train_data['labels']\n",
    "    dev_input_ids = dev_data['input_sent']\n",
    "    dev_target = dev_data['labels']\n",
    "    train_size=len(input_sent)\n",
    "    batch_size=BATCH_SIZE\n",
    "    batch_count=int(math.ceil(train_size)/batch_size)\n",
    "    model=EvidenceClassifier()\n",
    "    weights = torch.tensor([1.0,10.0])\n",
    "    \n",
    "    logging(model)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        weights = weights.cuda()\n",
    "    criterion = nn.NLLLoss(weight =weights, reduction='mean',ignore_index=2)\n",
    "    optimizer = AdamW(model.parameters(),lr=1e-05,correct_bias=False)\n",
    "    \n",
    "    logging(optimizer)\n",
    "    \n",
    "    best_dev_acc = -1\n",
    "    best_epoch_idx = -1\n",
    "    best_epoch_seed = -1\n",
    "    start_epoch = 0\n",
    "    ckp_path=os.path.join('checkpoint',model_name+'_checkpoint.pt')\n",
    "    best_epoch_idx,best_epoch_seed,best_dev_acc,start_epoch,model,optimizer=load_ckp(ckp_path, model, optimizer)\n",
    "    \n",
    "    for epoch_idx in range(start_epoch, EPOCH):\n",
    "        model.train()\n",
    "        # model.zero_grad()\n",
    "        logging('Epoch:', epoch_idx + 1)\n",
    "        cur_seed = RANDOM_SEED + epoch_idx + 1\n",
    "        set_random_seeds(cur_seed)\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "        train_loss_val = 0\n",
    "        is_best = False\n",
    "        \n",
    "        for batch_idx in tqdm(range(0,batch_count)):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(train_size,batch_start+batch_size)\n",
    "            data = get_batch_data(input_sent[batch_start:batch_end],target[batch_start:batch_end])\n",
    "            batch_sent_ids = torch.tensor(data['sent_ids']).to(torch.int64)\n",
    "            batch_sent_attention = torch.tensor(data['sent_attention']).to(torch.int64)\n",
    "            batch_sent_mask = torch.tensor(data['sent_mask']).to(torch.int64)\n",
    "            batch_evi_targets = torch.tensor(data['targets']).to(torch.int64)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                batch_sent_ids = batch_sent_ids.cuda()\n",
    "                batch_sent_attention = batch_sent_attention.cuda()\n",
    "                batch_sent_mask = batch_sent_mask.cuda()\n",
    "                batch_evi_targets = batch_evi_targets.cuda()\n",
    "            batch_sent_ids = autograd.Variable(batch_sent_ids)\n",
    "            batch_sent_attention = autograd.Variable(batch_sent_attention)\n",
    "            batch_sent_mask = autograd.Variable(batch_sent_mask)\n",
    "            batch_evi_targets = autograd.Variable(batch_evi_targets)\n",
    "            \n",
    "            outputs = model(batch_sent_ids,batch_sent_ids,batch_sent_mask,is_training=True)\n",
    "            y_pred = outputs.reshape((outputs.shape[0]*outputs.shape[1],outputs.shape[2]))\n",
    "            labels = batch_evi_targets.reshape((batch_evi_targets.shape[0]*batch_evi_targets.shape[1]))\n",
    "            loss = criterion(y_pred,labels)\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "            if (batch_idx + 1) % update_freq == 0:\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "            train_loss_val +=loss.item()\n",
    "        train_loss_val /=batch_count\n",
    "        end_time = datetime.datetime.now()\n",
    "        logging('Training_loss: ',train_loss_val)\n",
    "        logging('Time: ',end_time-start_time)\n",
    "        logging('\\nDev_Results\\n')\n",
    "        acc,F1 = predict(dev_data,model)\n",
    "        logging('Dev acc:',round(acc,3))\n",
    "        logging('Dev F1:',round(F1,3))\n",
    "        if F1 > best_dev_acc:\n",
    "            best_epoch_idx=epoch_idx+1\n",
    "            best_epoch_seed=cur_seed\n",
    "            logging(\"model saved ...\")\n",
    "            best_dev_acc=F1\n",
    "            torch.save(model.state_dict(),model_file)\n",
    "            is_best=True\n",
    "        checkpoint = {\n",
    "        'best_epoch_idx':best_epoch_idx,\n",
    "        'best_epoch_seed':best_epoch_seed,\n",
    "        'best_dev_acc':best_dev_acc,\n",
    "        'epoch':epoch_idx+1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        # save_ckp(checkpoint, is_best, 'checkpoint', 'checkpoint') # uncomment this when running for long time\n",
    "        logging('checkpoint updated\\n\\n')\n",
    "        if epoch_idx+1-best_epoch_idx>=early_stop_count:\n",
    "            break\n",
    "\n",
    "    logging(\"*\"*50)\n",
    "    logging('Best epoch',best_epoch_idx)\n",
    "    logging('Best Epoch Seed:', best_epoch_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dev_data,model,threshold=0.5):\n",
    "    dev_input_ids = dev_data['input_sent']\n",
    "    dev_target =dev_data['labels'] \n",
    "    dev_size=len(dev_input_ids)\n",
    "    batch_size=BATCH_SIZE_PRED\n",
    "    batch_count=int(math.ceil(dev_size/batch_size))\n",
    "    logging(\"Evidence Threshold:\",threshold)\n",
    "    model.eval()\n",
    "    set_random_seeds(RANDOM_SEED)\n",
    "    \n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    true_negative = 0\n",
    "    for batch_idx in tqdm(range(0,batch_count)):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = min(dev_size,batch_start+batch_size)\n",
    "        data = get_batch_data(dev_input_ids[batch_start:batch_end], dev_target[batch_start:batch_end])\n",
    "\n",
    "        batch_sent_ids = torch.tensor(data['sent_ids']).to(torch.int64)\n",
    "        batch_sent_attention = torch.tensor(data['sent_attention']).to(torch.int64)\n",
    "        batch_sent_mask = torch.tensor(data['sent_mask']).to(torch.int64)\n",
    "        batch_evi_targets = torch.tensor(data['targets']).to(torch.int64)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            batch_sent_ids = batch_sent_ids.cuda()\n",
    "            batch_sent_ids = batch_sent_attention.cuda()\n",
    "            batch_sent_mask = batch_sent_mask.cuda()\n",
    "            batch_evi_targets = batch_evi_targets.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_sent_ids,batch_sent_ids,batch_sent_mask,is_training=False)\n",
    "        for i in range(outputs.shape[0]):\n",
    "            for j in range(outputs.shape[1]):\n",
    "                if(batch_evi_targets[i][j]==2):\n",
    "                    continue\n",
    "                if outputs[i][j][1]>=threshold and batch_evi_targets[i][j]==1:\n",
    "                    true_positive+=1\n",
    "                elif outputs[i][j][1]>=threshold and batch_evi_targets[i][j]==0:\n",
    "                    false_positive+=1\n",
    "                elif outputs[i][j][1]<=threshold and batch_evi_targets[i][j]==1:\n",
    "                    false_negative+=1\n",
    "                else:\n",
    "                    true_negative+=1\n",
    "    logging('true_positive',true_positive)\n",
    "    logging('false_positive',false_positive)\n",
    "    logging('false_negative',false_negative)\n",
    "    logging('true_negative',true_negative)\n",
    "\n",
    "    preciscion = true_positive/(true_positive+false_positive+1e-05)\n",
    "    recall = true_positive/(true_positive+false_negative+1e-05)\n",
    "    F1 = 2*recall*preciscion/(preciscion+recall+1e-05)\n",
    "    acc = true_positive+true_negative\n",
    "    return acc,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EvidenceClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dense): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (logsoftmax): LogSoftmax()\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.999)\n",
      "    correct_bias: False\n",
      "    eps: 1e-06\n",
      "    lr: 1e-05\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]1\n",
      "100%|██████████| 27/27 [00:10<00:00,  2.50it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]Training_loss:  0.6078701129666081\n",
      "Time:  0:00:10.801893\n",
      "\n",
      "Dev_Results\n",
      "\n",
      "Evidence Threshold: 0.5\n",
      "100%|██████████| 41/41 [00:09<00:00,  4.46it/s]\n",
      "true_positive 347\n",
      "false_positive 1002\n",
      "false_negative 0\n",
      "true_negative 0\n",
      "Dev acc: 347\n",
      "Dev F1: 0.409\n",
      "model saved ...\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]checkpoint updated\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "100%|██████████| 27/27 [00:10<00:00,  2.49it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]Training_loss:  0.6091543469164107\n",
      "Time:  0:00:10.838996\n",
      "\n",
      "Dev_Results\n",
      "\n",
      "Evidence Threshold: 0.5\n",
      "100%|██████████| 41/41 [00:09<00:00,  4.35it/s]\n",
      "true_positive 347\n",
      "false_positive 1002\n",
      "false_negative 0\n",
      "true_negative 0\n",
      "Dev acc: 347\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]Dev F1: 0.409\n",
      "checkpoint updated\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "100%|██████████| 27/27 [00:16<00:00,  1.65it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]Training_loss:  0.5844328955367759\n",
      "Time:  0:00:16.415237\n",
      "\n",
      "Dev_Results\n",
      "\n",
      "Evidence Threshold: 0.5\n",
      "100%|██████████| 41/41 [00:15<00:00,  2.58it/s]\n",
      "true_positive 347\n",
      "false_positive 1002\n",
      "false_negative 0\n",
      "true_negative 0\n",
      "Dev acc: 347\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]Dev F1: 0.409\n",
      "checkpoint updated\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "100%|██████████| 27/27 [00:11<00:00,  2.30it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]Training_loss:  0.5712168161515836\n",
      "Time:  0:00:11.765531\n",
      "\n",
      "Dev_Results\n",
      "\n",
      "Evidence Threshold: 0.5\n",
      "100%|██████████| 41/41 [00:16<00:00,  2.43it/s]\n",
      "true_positive 347\n",
      "false_positive 1002\n",
      "false_negative 0\n",
      "true_negative 0\n",
      "Dev acc: 347\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]Dev F1: 0.409\n",
      "checkpoint updated\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "100%|██████████| 27/27 [00:14<00:00,  1.82it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]Training_loss:  0.5624094108740488\n",
      "Time:  0:00:14.848454\n",
      "\n",
      "Dev_Results\n",
      "\n",
      "Evidence Threshold: 0.5\n",
      "100%|██████████| 41/41 [00:17<00:00,  2.35it/s]\n",
      "true_positive 347\n",
      "false_positive 1002\n",
      "false_negative 0\n",
      "true_negative 0\n",
      "Dev acc: 347\n",
      "Dev F1: 0.409\n",
      "checkpoint updated\n",
      "\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]6\n",
      "100%|██████████| 27/27 [00:15<00:00,  1.78it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]Training_loss:  0.5600659361592045\n",
      "Time:  0:00:15.211888\n",
      "\n",
      "Dev_Results\n",
      "\n",
      "Evidence Threshold: 0.5\n",
      "100%|██████████| 41/41 [00:17<00:00,  2.31it/s]\n",
      "true_positive 347\n",
      "false_positive 1002\n",
      "false_negative 0\n",
      "true_negative 0\n",
      "Dev acc: 347\n",
      "Dev F1: 0.409\n",
      "checkpoint updated\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Best epoch 1\n",
      "Best Epoch Seed: 43\n"
     ]
    }
   ],
   "source": [
    "train(train_data = train_data,dev_data = dev_data, model_file=save_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import sys\n",
    "# print('A', sys.version)\n",
    "# print('B', torch.__version__)\n",
    "# print('C', torch.cuda.is_available())\n",
    "# print('D', torch.backends.cudnn.enabled)\n",
    "# device = torch.device('cuda')\n",
    "# print('E', torch.cuda.get_device_properties(device))\n",
    "# print('F', torch.tensor([1.0, 2.0]).cuda())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0c1a6acda623edd715f82c47267c573bc809bf1b0ea7f0535e6ec198d9dd2e2d9",
   "display_name": "Python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "c1a6acda623edd715f82c47267c573bc809bf1b0ea7f0535e6ec198d9dd2e2d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}